{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WV5fR3sotHXp",
        "m-VVH3V36y8y",
        "m-VVH3V36y8w"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0bdc64b7290a4866977be8db6939c15f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Videos:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_9b6412b117fa4ed699fd3074281bca63",
            "placeholder": "Enter list of video URIs here (one per line or use commas)...",
            "rows": null,
            "style": "IPY_MODEL_1c7d201eccc24ec69c45a1613c347a8c",
            "value": "gs://abcd-detector-input/Google/videos/"
          }
        },
        "9b6412b117fa4ed699fd3074281bca63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "200px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "90%"
          }
        },
        "1c7d201eccc24ec69c45a1613c347a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30842f089cff45ec9ba21ef68230da6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Load Video URIs",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_4cb8331363344368918facaa5826fafb",
            "style": "IPY_MODEL_b4009e7a854b4c52b1e9b8fdb0485a5f",
            "tooltip": ""
          }
        },
        "4cb8331363344368918facaa5826fafb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4009e7a854b4c52b1e9b8fdb0485a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Copyright 2024 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "mbQ34wkyzuMv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ABCDs Detector\n",
        "\n",
        "The ABCDs Detector solution offers a streamlined solution for understanding how video ads align with key metrics within the [YouTube ABCD Framework](https://www.thinkwithgoogle.com/intl/en-emea/future-of-marketing/creativity/youtube-video-ad-best-practices/). Powered by Google AI, the tool leverages a data-driven analysis to automate the ABCD assessment, providing an objective and comprehensive report of adherence across a collection of defined features. By combining **Video** And **LLM** Google AI models, ABCDs Detector automates the evaluation process and delivers comprehensive reports on how well your ads align with the ABCD framework. This empowers you to optimize your YouTube ad campaigns for maximum impact."
      ],
      "metadata": {
        "id": "WV5fR3sotHXp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Video Intelligence API (Video)\n",
        "\n",
        "Google AI extracts features and identifies key moments within your video ads. See [Google Video Intelligence API](https://cloud.google.com/video-intelligence?hl=en) documentation.\n",
        "\n",
        "### Features Used\n",
        "  - Label annotations\n",
        "  - Face annotations\n",
        "  - Text annotations\n",
        "  - Object annotations\n",
        "  - People annotations\n",
        "  - Speech annotations\n",
        "  - Shot annotations\n",
        "  - Logo annotations\n",
        "\n",
        "### Cost\n",
        "Prices are per minute. Partial minutes are rounded up to the next full minute. Volume is per month. For more details please check the official [documentation](https://cloud.google.com/video-intelligence/pricing).\n",
        "\n"
      ],
      "metadata": {
        "id": "qDLbAgObvWGv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gemini Pro (LLM)\n",
        "\n",
        "LLMs are used to assess features against YouTube's ABCD framework rubrics. This enables the detector to \"ask questions\" and determine if the ad adheres to each rubric.  See [Vertex AI](https://cloud.google.com/vertex-ai) documentation.\n",
        "\n",
        "### Prompts\n",
        "\n",
        "ABCDs Detector will perform 2 verifications, first with annotations and then with LLMs. Since the LLM approach is prone to hallucinations, False Positives or False Negatives will be expected. The solution will still require human QA if 100% accuracy is required for the evaluation.\n",
        "\n",
        "ABCDs Detector MVP supports a single video evaluation for the following features/rubrics:\n",
        "  - Quick Pacing\n",
        "  - Quick Pacing (First 5 seconds)\n",
        "  - Dynamic Start\n",
        "  - Supers\n",
        "  - Supers with Audio\n",
        "  - Brand Visuals\n",
        "  - Brand Visuals (First 5 seconds)\n",
        "  - Brand Mention (Speech)\n",
        "  - Brand Mention (Speech) (First 5 seconds)\n",
        "  - Product Visuals\n",
        "  - Product Visuals (First 5 seconds)\n",
        "  - Product Mention (Text)\n",
        "  - Product Mention (Text) (First 5 seconds)\n",
        "  - Product Mention (Speech)\n",
        "  - Product Mention (Speech) (First 5 seconds)\n",
        "  - Visible Face (First 5 seconds)\n",
        "  - Visible Face (Close Up)\n",
        "  - Presence of People\n",
        "  - Presence of People (First 5 seconds)\n",
        "  - Overall Pacing\n",
        "  - Audio Speech Early\n",
        "  - Call To Action (Text)\n",
        "  - Call To Action (Speech)\n",
        "\n",
        "### Cost\n",
        "With the Multimodal models in Vertex AI, you can input either text or media (images, video). Text input is charged by every 1,000 characters of input (prompt) and every 1,000 characters of output (response). Characters are counted by UTF-8 code points and white space is excluded from the count. Prediction requests that lead to filtered responses are charged for the input only. At the end of each billing cycle, fractions of one cent ($0.01) are rounded to one cent. Media input is charged per image or per second (video). For more details please check the official documentation: https://cloud.google.com/vertex-ai/generative-ai/pricing\n"
      ],
      "metadata": {
        "id": "eCRbyHkLt4Di"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements\n",
        "Please esure you have access to all of the following before starting:\n",
        "* [Google Cloud Project](https://cloud.google.com) with enabled APIs:\n",
        "    * [Video Intelligence API](https://console.cloud.google.com/marketplace/product/google/videointelligence.googleapis.com)\n",
        "    * [Vertex AI API](https://console.cloud.google.com/marketplace/product/google/aiplatform.googleapis.com)\n",
        "    * [Knowledge Graph API](https://console.cloud.google.com/marketplace/product/google/kgsearch.googleapis.com)\n",
        "    * [Cloud Storage API](https://console.cloud.google.com/marketplace/product/google/storage.googleapis.com)\n",
        "* [API Key](https://cloud.google.com/docs/authentication/api-keys) provisioned.\n",
        "* [Project Billing](https://cloud.google.google.com/billing/) enabled.\n",
        "* Python libraries:\n",
        "    * `google-cloud-videointelligence`\n",
        "    * `google-cloud-aiplatform`"
      ],
      "metadata": {
        "id": "e7rvNc74z-b5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions\n",
        "Please follow the steps below before executing the ABCDs Detector solution. Every **[VARIABLE]** is a parameter you can configure in the **Define ABCDs Detector Parameters** section.\n",
        "\n",
        "1. Store your videos on [Google Cloud Storage](https://console.cloud.google.com/storage/browser).\n",
        "   * **[BUCKET_NAME]** - the place where this tool will store annotation data under **ABCD** folder. Clear this to redo annotations.\n",
        "   * **[VIDEO_URIS]** - a list of video URIs that will be processed, can be any path but should match brand information.\n",
        "      * If the URI is a file if will be evaluated as is.\n",
        "      * If the URI is a folder path that ends with **/**, then it will be expanded, all the files in that path will be evaluated.\n",
        "\n",
        "1. Make sure the requirements are met:\n",
        "   * Enable APIs:\n",
        "      * [Video Intelligence API](https://console.cloud.google.com/marketplace/product/google/videointelligence.googleapis.com)\n",
        "      * [Vertex AI API](https://console.cloud.google.com/marketplace/product/google/aiplatform.googleapis.com)\n",
        "      * [Knowledge Graph API](https://console.cloud.google.com/marketplace/product/google/kgsearch.googleapis.com)\n",
        "      * [Cloud Storage API](https://console.cloud.google.com/marketplace/product/google/storage.googleapis.com)\n",
        "   * Provision [An API Key](https://cloud.google.com/docs/authentication/api-keys):\n",
        "      1. Visit [Credentials Page](https://cloud.console.google.com/apis/credentials).\n",
        "      1. Create a **New API Key** and copy it into **[KNOWLEDGE_GRAPH_API_KEY]** below.\n",
        "      1. We recommend editing and restricting the key to the above APIs.\n",
        "\n",
        "1. Define all the parameters.\n",
        "   * Required:\n",
        "      * Google Cloud Project Details\n",
        "      * Brand And Product Details\n",
        "   * Optional\n",
        "      * Solution Setup\n",
        "      * ABCD Framework Details\n",
        "      * LLM Configuration\n",
        "\n",
        "1. Run all of the steps in sequence.\n",
        "   * Some steps do not produce output, they only define functions.\n",
        "   * If a step asks you to **Restart Runtime**, do so.\n",
        "   * If a step displays an error, stop and debug it. Debug the following:\n",
        "      * APIs are enabled.\n",
        "      * Storage bucket is correctly configured.\n",
        "      * The video is the correct size.\n",
        "      * API Key has correct restrictions.\n",
        "      * Previous code sections completed.\n",
        "      * Select _Runtime > Reset Session and Run All_ as a last resort.\n",
        "   * The **Run Bulk ABCDs Detector** produces the video analysis.\n",
        "\n",
        "1. For questions, please reach out to: abcds-detector@google.com"
      ],
      "metadata": {
        "id": "XHqQskKjxtEk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install ABCD Detector Code"
      ],
      "metadata": {
        "id": "m-VVH3V36y8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/google-marketing-solutions/abcds-detector\n",
        "!python3 -m pip install -r \"abcds-detector/requirements.txt\"\n",
        "%cd /content/abcds-detector"
      ],
      "metadata": {
        "id": "3KlVPryttrZr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fd417fa-7dca-4082-802f-ca4e7d813ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'abcds-detector'...\n",
            "remote: Enumerating objects: 270, done.\u001b[K\n",
            "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 270 (delta 42), reused 57 (delta 32), pack-reused 178 (from 1)\u001b[K\n",
            "Receiving objects: 100% (270/270), 2.35 MiB | 13.66 MiB/s, done.\n",
            "Resolving deltas: 100% (150/150), done.\n",
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (from -r abcds-detector/requirements.txt (line 1)) (1.67.1)\n",
            "Collecting google-cloud-videointelligence (from -r abcds-detector/requirements.txt (line 2))\n",
            "  Downloading google_cloud_videointelligence-2.13.5-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (from -r abcds-detector/requirements.txt (line 3)) (2.8.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (from -r abcds-detector/requirements.txt (line 4)) (1.0.3)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from -r abcds-detector/requirements.txt (line 5)) (2.137.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r abcds-detector/requirements.txt (line 6)) (2.1.4)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from -r abcds-detector/requirements.txt (line 7)) (14.0.2)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform->-r abcds-detector/requirements.txt (line 1)) (2.19.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r abcds-detector/requirements.txt (line 1)) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r abcds-detector/requirements.txt (line 1)) (1.24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r abcds-detector/requirements.txt (line 1)) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r abcds-detector/requirements.txt (line 1)) (24.1)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r abcds-detector/requirements.txt (line 1)) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r abcds-detector/requirements.txt (line 1)) (1.12.5)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r abcds-detector/requirements.txt (line 1)) (2.0.6)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r abcds-detector/requirements.txt (line 1)) (2.9.2)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform->-r abcds-detector/requirements.txt (line 1)) (0.16)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->-r abcds-detector/requirements.txt (line 3)) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->-r abcds-detector/requirements.txt (line 3)) (2.7.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->-r abcds-detector/requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r abcds-detector/requirements.txt (line 4)) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r abcds-detector/requirements.txt (line 4)) (4.66.5)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r abcds-detector/requirements.txt (line 4)) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r abcds-detector/requirements.txt (line 4)) (1.26.4)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r abcds-detector/requirements.txt (line 4)) (2.35.1)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r abcds-detector/requirements.txt (line 4)) (0.5.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->-r abcds-detector/requirements.txt (line 5)) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->-r abcds-detector/requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->-r abcds-detector/requirements.txt (line 5)) (4.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r abcds-detector/requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r abcds-detector/requirements.txt (line 6)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r abcds-detector/requirements.txt (line 6)) (2024.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform->-r abcds-detector/requirements.txt (line 1)) (1.65.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform->-r abcds-detector/requirements.txt (line 1)) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform->-r abcds-detector/requirements.txt (line 1)) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform->-r abcds-detector/requirements.txt (line 1)) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform->-r abcds-detector/requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform->-r abcds-detector/requirements.txt (line 1)) (4.9)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform->-r abcds-detector/requirements.txt (line 1)) (0.13.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage->-r abcds-detector/requirements.txt (line 3)) (1.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->-r abcds-detector/requirements.txt (line 5)) (3.1.4)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy->-r abcds-detector/requirements.txt (line 4)) (10.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy->-r abcds-detector/requirements.txt (line 4)) (71.0.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform->-r abcds-detector/requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform->-r abcds-detector/requirements.txt (line 1)) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3->google-cloud-aiplatform->-r abcds-detector/requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->-r abcds-detector/requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->-r abcds-detector/requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->-r abcds-detector/requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->-r abcds-detector/requirements.txt (line 3)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->-r abcds-detector/requirements.txt (line 3)) (2024.8.30)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform->-r abcds-detector/requirements.txt (line 1)) (0.6.1)\n",
            "Downloading google_cloud_videointelligence-2.13.5-py2.py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.0/245.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-cloud-videointelligence\n",
            "Successfully installed google-cloud-videointelligence-2.13.5\n",
            "/content/abcds-detector\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define ABCDs Detector Parameters"
      ],
      "metadata": {
        "id": "m-VVH3V36y8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "###########################################################################\n",
        "#\n",
        "#  Copyright 2024 Google LLC\n",
        "#\n",
        "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "#  you may not use this file except in compliance with the License.\n",
        "#  You may obtain a copy of the License at\n",
        "#\n",
        "#      https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "#  Unless required by applicable law or agreed to in writing, software\n",
        "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "#  See the License for the specific language governing permissions and\n",
        "#  limitations under the License.\n",
        "#\n",
        "###########################################################################\n",
        "\n",
        "\"\"\"Module that defines the colab parameters\"\"\"\n",
        "\n",
        "import os\n",
        "import input_parameters\n",
        "\n",
        "# @markdown ### Google Cloud Project Details\n",
        "\n",
        "input_parameters.PROJECT_ID = \"\"  # @param {type:\"string\", placeholder:\"Google Cloud Project ID\"}\n",
        "input_parameters.BUCKET_NAME = \"\"  # @param {type:\"string\", placeholder:\"Google Cloud Sotrage Bucket for annotations\"}\n",
        "input_parameters.ANNOTATION_PATH = f\"gs://{input_parameters.BUCKET_NAME}/ABCD/\"\n",
        "\n",
        "input_parameters.VIDEO_URIS = [\n",
        "    \"gs://cloud-samples-data/generative-ai/video/pixel8.mp4\",\n",
        "]  # use helpers/input_helper.py to load this\n",
        "\n",
        "input_parameters.FFMPEG_BUFFER = \"reduced/buffer.mp4\"\n",
        "input_parameters.FFMPEG_BUFFER_REDUCED = \"reduced/buffer_reduced.mp4\"\n",
        "if not os.path.exists(\"reduced\"):\n",
        "    os.makedirs(\"reduced\")\n",
        "\n",
        "# @markdown ### Solution Setup\n",
        "\n",
        "input_parameters.VIDEO_SIZE_LIMIT_MB = 50  # @param {type:\"number\"}\n",
        "input_parameters.VERBOSE = True  # @param {type:\"boolean\"}\n",
        "input_parameters.USE_ANNOTATIONS = True  # @param {type:\"boolean\"}\n",
        "input_parameters.USE_LLMS = True  # @param {type:\"boolean\"}\n",
        "# For local testing outside colab ONLY, set to False for colab\n",
        "input_parameters.ASSESSMENT_FILE = \"\"  # @param {type:\"string\", placeholder:\"optional local file to write assesments to\"}\n",
        "\n",
        "\n",
        "# @markdown #### Knowledge Graph API Configuration\n",
        "\n",
        "input_parameters.KNOWLEDGE_GRAPH_API_KEY = \"\"  # @param {type:\"string\", placeholder:\"Google Cloud Project API Key\"}\n",
        "\n",
        "# @markdown ### Brand and Product Details\n",
        "\n",
        "input_parameters.brand_name = \"Google\"  # @param {type:\"string\"}\n",
        "input_parameters.brand_variations_str = \"google\"  # @param {type:\"string\"}\n",
        "input_parameters.branded_products_str = \"Google pixel, Google pixel buds, Google pixel watch\"  # @param {type:\"string\"}\n",
        "input_parameters.branded_products_categories_str = \"phone, watch, buds\"  # @param {type:\"string\"}\n",
        "input_parameters.branded_call_to_actions_str = \"buy it!\"  # @param {type:\"string\"}\n",
        "\n",
        "\n",
        "# @markdown ### ABCD Framework Details\n",
        "\n",
        "# @markdown #### ABCD Assessment Thresholds\n",
        "input_parameters.early_time_seconds = 5\n",
        "input_parameters.confidence_threshold = 0.5  # @param {type:\"number\"}\n",
        "input_parameters.face_surface_threshold = 0.15  # @param {type:\"number\"}\n",
        "input_parameters.logo_size_threshold = 3.5  # @param {type:\"number\"}\n",
        "input_parameters.avg_shot_duration_seconds = 2  # @param {type:\"number\"}\n",
        "input_parameters.dynamic_cutoff_ms = 3000  # @param {type:\"number\"}\n",
        "\n",
        "\n",
        "# @markdown ### LLM Configuration\n",
        "\n",
        "# @markdown #### LLM names and versions\n",
        "\n",
        "input_parameters.LLM_NAME = \"gemini-1.5-pro-002\"  # @param {type:\"string\"}\n",
        "input_parameters.llm_location = \"us-central1\"  # @param {type:\"string\"}\n",
        "input_parameters.max_output_tokens = 8192  # @param {type:\"number\"}\n",
        "input_parameters.temperature = 1  # @param {type:\"number\"}\n",
        "input_parameters.top_p = 0.95  # @param {type:\"number\"}\n",
        "input_parameters.top_k = 32  # @param {type:\"number\"}\n",
        "\n",
        "\n",
        "# @markdown ### BigQuery Configuration\n",
        "\n",
        "# @markdown #### BQ dataset and table\n",
        "\n",
        "input_parameters.STORE_IN_BQ = True # @param {type:\"boolean\"}\n",
        "input_parameters.BQ_DATASET_NAME = \"abcd_detector_ds\" # @param {type:\"string\"}\n",
        "input_parameters.BQ_TABLE_NAME = \"abcd_assessments\" # @param {type:\"string\"}\n",
        "input_parameters.BQ_LOCATION = \"us-central1\"\n",
        "\n",
        "### DO NOT EDIT, vars built from user's input ###\n",
        "def convert_string_to_list(list_str: str):\n",
        "    \"\"\"Converts a string to a list and\n",
        "    removes white spaces from strings in list\n",
        "    Args:\n",
        "        list_str\n",
        "    \"\"\"\n",
        "    cleaned_list = []\n",
        "    for item in list_str.split(\",\"):\n",
        "        cleaned_list.append(item.strip())\n",
        "    return cleaned_list\n",
        "\n",
        "\n",
        "input_parameters.brand_variations = input_parameters.convert_string_to_list(input_parameters.brand_variations_str)\n",
        "input_parameters.brand_variations.append(input_parameters.brand_name)\n",
        "input_parameters.branded_products = input_parameters.convert_string_to_list(input_parameters.branded_products_str)\n",
        "input_parameters.branded_products_categories = input_parameters.convert_string_to_list(input_parameters.branded_products_categories_str)\n",
        "input_parameters.branded_call_to_actions = input_parameters.convert_string_to_list(input_parameters.branded_call_to_actions_str)\n",
        "\n",
        "if input_parameters.VERBOSE:\n",
        "    print(\"ABCD Detector parameters: \\n\")\n",
        "    print(f\"Brand variations: {input_parameters.brand_variations}\")\n",
        "    print(f\"Brand products: {input_parameters.branded_products}\")\n",
        "    print(f\"Brand categories: {input_parameters.branded_products_categories}\")\n",
        "    print(f\"Brand call to actions: {input_parameters.branded_call_to_actions} \\n\")\n",
        "\n",
        "llm_generation_config = {\n",
        "    \"max_output_tokens\": input_parameters.max_output_tokens,\n",
        "    \"temperature\": input_parameters.temperature,\n",
        "    \"top_p\": input_parameters.top_p,\n",
        "    \"top_k\": input_parameters.top_k,\n",
        "}\n"
      ],
      "metadata": {
        "id": "myojeXOC0UYJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d37cf08-4e6f-423d-b47c-8c6953e2ce20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ABCD Detector parameters: \n",
            "\n",
            "Brand variations: ['google', 'Google']\n",
            "Brand products: ['Google pixel', 'Google pixel buds', 'Google pixel watch']\n",
            "Brand categories: ['phone', 'watch', 'buds']\n",
            "Brand call to actions: ['buy it!'] \n",
            "\n",
            "ABCD Detector parameters: \n",
            "\n",
            "Brand variations: ['google', 'Google']\n",
            "Brand products: ['Google pixel', 'Google pixel buds', 'Google pixel watch']\n",
            "Brand categories: ['phone', 'watch', 'buds']\n",
            "Brand call to actions: ['buy it!'] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "videos_textarea = widgets.Textarea(\n",
        "  value='\\n'.join(input_parameters.VIDEO_URIS),\n",
        "  placeholder='Enter list of video URIs here (one per line or use commas)...',\n",
        "  description='Videos:',\n",
        "  layout=widgets.Layout(width='90%', height='200px')\n",
        ")\n",
        "\n",
        "# Create a button widget\n",
        "videos_button = widgets.Button(\n",
        "  description='Load Video URIs',\n",
        "  button_style='success'\n",
        ")\n",
        "\n",
        "def videos_load(button):\n",
        "  input_parameters.VIDEO_URIS = [uri.strip() for uri in videos_textarea.value.replace(',', '\\n').split('\\n')]\n",
        "  print('\\nLOADED!\\n')\n",
        "\n",
        "videos_button.on_click(videos_load)\n",
        "display(videos_textarea, videos_button)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305,
          "referenced_widgets": [
            "0bdc64b7290a4866977be8db6939c15f",
            "9b6412b117fa4ed699fd3074281bca63",
            "1c7d201eccc24ec69c45a1613c347a8c",
            "30842f089cff45ec9ba21ef68230da6b",
            "4cb8331363344368918facaa5826fafb",
            "b4009e7a854b4c52b1e9b8fdb0485a5f"
          ]
        },
        "id": "8QYDMXFj1EJK",
        "outputId": "0e1e31fd-2c80-42ee-a08e-3b549295a33c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Textarea(value='gs://cloud-samples-data/generative-ai/video/pixel8.mp4', description='Videos:', layout=Layout(…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bdc64b7290a4866977be8db6939c15f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='Load Video URIs', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30842f089cff45ec9ba21ef68230da6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LOADED!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Authenticate"
      ],
      "metadata": {
        "id": "fz86-SgmRBc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user(project_id=input_parameters.PROJECT_ID)"
      ],
      "metadata": {
        "id": "Ovcu5_OXGHy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run ABCDs Detector"
      ],
      "metadata": {
        "id": "pg9ZT-CERKzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from main import execute_abcd_detector\n",
        "execute_abcd_detector()"
      ],
      "metadata": {
        "id": "0-92Uo3Ova_g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1234e0f8-4d88-483e-db02-dc5d0c6077fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting ABCD assessment... \n",
            "\n",
            "EXPANDING URI: gs://abcd-detector-input/Google/videos/ \n",
            "\n",
            "\n",
            "\n",
            "Processing ABCD Assessment for video gs://abcd-detector-input/Google/videos/12345_google_pixel_portfolio.mp4... \n",
            "\n",
            "REDUCED: gs://abcd-detector-input/ABCD/abcd-detector-input/Google/videos/12345_google_pixel_portfolio_mp4/reduced_1st_5_secs.mp4 \n",
            "\n",
            "Shortening video gs://abcd-detector-input/Google/videos/12345_google_pixel_portfolio.mp4. \n",
            "\n",
            "Moviepy - Building video reduced/buffer_reduced.mp4.\n",
            "MoviePy - Writing audio in buffer_reducedTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video reduced/buffer_reduced.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready reduced/buffer_reduced.mp4\n",
            "\n",
            "Processing video gs://abcd-detector-input/Google/videos/12345_google_pixel_portfolio.mp4 for [<Feature.TEXT_DETECTION: 7>, <Feature.SHOT_CHANGE_DETECTION: 2>, <Feature.LOGO_RECOGNITION: 12>, <Feature.LABEL_DETECTION: 1>] annotations...\n",
            "\n",
            "Processing video gs://abcd-detector-input/Google/videos/12345_google_pixel_portfolio.mp4 for [<Feature.FACE_DETECTION: 4>] annotations...\n",
            "\n",
            "Processing video gs://abcd-detector-input/Google/videos/12345_google_pixel_portfolio.mp4 for [<Feature.PERSON_DETECTION: 14>] annotations...\n",
            "\n",
            "Processing video gs://abcd-detector-input/Google/videos/12345_google_pixel_portfolio.mp4 for [<Feature.SPEECH_TRANSCRIPTION: 6>] annotations...\n",
            "\n",
            "Finished processing video gs://abcd-detector-input/Google/videos/12345_google_pixel_portfolio.mp4 for [<Feature.FACE_DETECTION: 4>] annotations...\n",
            "\n",
            "\n",
            "Finished processing video gs://abcd-detector-input/Google/videos/12345_google_pixel_portfolio.mp4 for [<Feature.TEXT_DETECTION: 7>, <Feature.SHOT_CHANGE_DETECTION: 2>, <Feature.LOGO_RECOGNITION: 12>, <Feature.LABEL_DETECTION: 1>] annotations...\n",
            "\n",
            "\n",
            "Finished processing video gs://abcd-detector-input/Google/videos/12345_google_pixel_portfolio.mp4 for [<Feature.PERSON_DETECTION: 14>] annotations...\n",
            "\n",
            "\n",
            "Finished processing video gs://abcd-detector-input/Google/videos/12345_google_pixel_portfolio.mp4 for [<Feature.SPEECH_TRANSCRIPTION: 6>] annotations...\n",
            "\n",
            "Starting ABCD evaluation using annotations... \n",
            "\n",
            "Annotation evaluation for feature Dynamic Start...\n",
            "Dynamic Start: True \n",
            "\n",
            "Annotation evaluation for feature Quick Pacing...\n",
            "Quick Pacing: True \n",
            "\n",
            "Annotation evaluation for feature Quick Pacing (First 5 seconds)...\n",
            "Quick Pacing (First 5 seconds): True \n",
            "\n",
            "Annotation evaluation for feature Supers...\n",
            "Supers: True \n",
            "\n",
            "Annotation evaluation for feature Supers with Audio...\n",
            "Supers with Audio: False \n",
            "\n",
            "Annotation evaluation for feature Brand Mention (Speech)...\n",
            "Brand Mention (Speech): False \n",
            "\n",
            "Annotation evaluation for feature Brand Mention (Speech) (First 5 seconds)...\n",
            "Brand Mention (Speech) (First 5 seconds): False \n",
            "\n",
            "Annotation evaluation for feature Brand Visuals...\n",
            "Brand Visuals: True \n",
            "\n",
            "Annotation evaluation for feature Brand Visuals (First 5 seconds)...\n",
            "Brand Visuals (First 5 seconds): True \n",
            "\n",
            "Annotation evaluation for feature Product Mention (Speech)...\n",
            "Product Mention (Speech): False \n",
            "\n",
            "Annotation evaluation for feature Product Mention (Speech) (First 5 seconds)...\n",
            "Product Mention (Speech) (First 5 seconds): False \n",
            "\n",
            "Annotation evaluation for feature Product Mention (Text)...\n",
            "Product Mention (Text): True \n",
            "\n",
            "Annotation evaluation for feature Product Mention (Text) (First 5 seconds)...\n",
            "Product Mention (Text) (First 5 seconds): False \n",
            "\n",
            "Annotation evaluation for feature Product Visuals...\n",
            "No Frame Label annotations found. Skipping Product Visuals Frame Label evaluation with Video Intelligence API.\n",
            "Product Visuals: True \n",
            "\n",
            "Annotation evaluation for feature Product Visuals (First 5 seconds)...\n",
            "No Frame Label annotations found. Skipping Product Visuals (First 5 seconds) Frame Label evaluation with Video Intelligence API.\n",
            "Product Visuals (First 5 seconds): True \n",
            "\n",
            "Annotation evaluation for feature Overall Pacing...\n",
            "Overall Pacing: True \n",
            "\n",
            "Annotation evaluation for feature Presence of People...\n",
            "No People annotations found. Skipping Presence of People evaluation with Video Intelligence API.\n",
            "Presence of People: False \n",
            "\n",
            "Annotation evaluation for feature Presence of People (First 5 seconds)...\n",
            "No People annotations found. Skipping Presence of People (First 5 seconds) evaluation with Video Intelligence API.\n",
            "Presence of People (First 5 seconds): False \n",
            "\n",
            "Annotation evaluation for feature Visible Face (First 5 seconds)...\n",
            "No Face annotations found. Skipping Visible Face (First 5 seconds) evaluation with Video Intelligence API.\n",
            "Visible Face (First 5 seconds): False \n",
            "\n",
            "Annotation evaluation for feature Visible Face (Close Up)...\n",
            "No Face annotations found. Skipping Visible Face (Close Up) evaluation with Video Intelligence API.\n",
            "Visible Face (Close Up): False \n",
            "\n",
            "Annotation evaluation for feature Audio Early (First 5 seconds)...\n",
            "Audio Early (First 5 seconds): False \n",
            "\n",
            "Annotation evaluation for feature Call To Action (Speech)...\n",
            "Call To Action (Speech): False \n",
            "\n",
            "Annotation evaluation for feature Call To Action (Text)...\n",
            "Call To Action (Text): False \n",
            "\n",
            "Starting ABCD evaluation using LLMs... \n",
            "\n",
            "Starting LLM evaluation for features grouped by first_5_secs_video... \n",
            "\n",
            "Starting LLM evaluation for features grouped by full_video... \n",
            "\n",
            "***Powered by LLMs*** \n",
            "\n",
            " FEATURES in group first_5_secs_video: \n",
            "\n",
            " [{'category': 'Attract', 'criteria': 'The first shot in the video changes in less than 3 seconds.', 'detected': True, 'id': 'a_dynamic_start', 'llm_explanation': 'The first shot of the Google Pixel watch with an orange band changes at timestamp [00:00:01] to a light blue Google Pixel phone. This shot change occurs within 3 seconds from the start of the video.', 'name': 'Dynamic Start'}, {'category': 'Attract', 'criteria': 'There are at least 5 shot changes or visual cuts detected in the video. These include hard cuts, soft transitions and camera changes such as camera pans, swipes, zooms, depth of field changes, tracking shots and movement of the camera.', 'detected': True, 'id': 'a_quick_pacing_1st_secs', 'llm_explanation': 'There are at least five visual cuts in the video within the first five seconds. Number of shots: 6\\n[00:00:00] Google Pixel watch with an orange band\\n[00:00:01] Light blue Google Pixel phone\\n[00:00:02] Google Pixel watch with light blue band\\n[00:00:03] Google Pixel buds with light blue tips\\n[00:00:04] The only\\n[00:00:05] pixel', 'name': 'Quick Pacing (First 5 seconds)'}, {'category': 'Brand', 'criteria': 'The brand name is heard in the audio or speech in the video.', 'detected': False, 'id': 'b_brand_mention_speech_1st_5_secs', 'llm_explanation': 'The brand name \"Google\" is not mentioned in the speech of the video within the first five seconds.', 'name': 'Brand Mention (Speech) (First 5 seconds)'}, {'category': 'Brand', 'criteria': 'Branding, defined as the brand name or brand logo are shown in-situation or overlaid in the video.', 'detected': True, 'id': 'b_brand_visuals_1st_5_secs', 'llm_explanation': 'At [00:00:05] the brand name Google can be seen overlaid in the video.', 'name': 'Brand Visuals (First 5 seconds)'}, {'category': 'Brand', 'criteria': 'The branded product names or generic product categories are heard or mentioned in the audi or speech in the the video.', 'detected': False, 'id': 'b_product_mention_speech_1st_5_secs', 'llm_explanation': 'No branded product names or generic product categories are heard in the speech of the video.', 'name': 'Product Mention (Speech) (First 5 seconds)'}, {'category': 'Brand', 'criteria': 'The branded product names or generic product categories are present in any text or overlay in the video.', 'detected': True, 'id': 'b_product_mention_text_1st_5_secs', 'llm_explanation': 'The branded product name Google Pixel is found in text at [00:00:05]', 'name': 'Product Mention (Text) (First 5 seconds)'}, {'category': 'Brand', 'criteria': 'A product or branded packaging is visually present at any time in the video. Where the product is a service a relevant substitute should be shown such as via a branded app or branded service personnel.', 'detected': True, 'id': 'b_product_visuals_1st_5_secs', 'llm_explanation': 'The products Google Pixel phone [00:00:01], Google Pixel watch [00:00:00] and Google Pixel buds [00:00:03] are all shown within the first five seconds.', 'name': 'Product Visuals (First 5 seconds)'}, {'category': 'Connect', 'criteria': 'People are shown in any capacity in the video. Any human body parts are acceptable to pass this guideline. Alternate representations of people such as Animations or Cartoons ARE acceptable.', 'detected': False, 'id': 'c_presence_of_people_1st_5_secs', 'llm_explanation': 'No people are shown in the video during the first five seconds.', 'name': 'Presence of People (First 5 seconds)'}, {'category': 'Connect', 'criteria': 'At least one human face is present in the video. Alternate representations of people such as Animations or Cartoons ARE acceptable.', 'detected': False, 'id': 'c_visible_face', 'llm_explanation': 'No human faces are present in the video.', 'name': 'Visible Face (First 5 seconds)'}, {'category': 'Direct', 'criteria': 'Speech is detected in the audio of the video.', 'detected': False, 'id': 'd_audio_speech_early_1st_5_secs', 'llm_explanation': 'There is no speech detected in the audio of the video.', 'name': 'Audio Early (First 5 seconds)'}] \n",
            "\n",
            "***Powered by LLMs*** \n",
            "\n",
            " FEATURES in group full_video: \n",
            "\n",
            " [{'category': 'Attract', 'criteria': 'Within ANY 5 consecutive seconds there are 5 or more shots in the video. These include hard cuts, soft transitions and camera changes such as camera pans, swipes, zooms, depth of field changes, tracking shots and movement of the camera.', 'detected': True, 'id': 'a_quick_pacing', 'llm_explanation': \"Number of shots: 6\\n[00:00:00] Google Pixel watch with a red band.\\n[00:00:01] Google Pixel phone.\\n[00:00:02] Google Pixel watch with a blue band.\\n[00:00:03] Google Pixel buds in a white case.\\n[00:00:04] Text 'The only'.\\n[00:00:05] Multiple Google pixel phones.\\nThe video has at least 5 shots changes within 5 seconds.\", 'name': 'Quick Pacing'}, {'category': 'Attract', 'criteria': 'Any supers (text overlays) have been incorporated at any time in the video.', 'detected': True, 'id': 'a_supers', 'llm_explanation': 'The following supers are found in the video:\\n[00:00:04] The only\\n[00:00:05] phone\\n[00:00:07] watch\\n[00:00:08] buds\\n[00:00:11] engineered by\\n[00:00:12] Google\\n[00:00:13] Google Pixel 8', 'name': 'Supers'}, {'category': 'Attract', 'criteria': 'The speech heard in the audio of the video matches OR is contextually supportive of the overlaid text shown on screen.', 'detected': False, 'id': 'a_supers_with_audio', 'llm_explanation': 'There is no audio or speech in the video, therefore, there are no matching or contextually supportive supers with audio in the video.', 'name': 'Supers with Audio'}, {'category': 'Brand', 'criteria': 'The brand name is heard in the audio or speech at any time in the video.', 'detected': False, 'id': 'b_brand_mention_speech', 'llm_explanation': 'There is no audio in the video, therefore the brand name Google is not mentioned.', 'name': 'Brand Mention (Speech)'}, {'category': 'Brand', 'criteria': 'Branding, defined as the brand name or brand logo are shown in-situation or overlaid at any time in the video.', 'detected': True, 'id': 'b_brand_visuals', 'llm_explanation': 'Brand logo Google is visible at [00:00:00] on the watch, at [00:00:05] on the phones, at [00:00:09] on the Pixel buds and at [00:00:12]-[00:00:14]. The brand Google is visible at [00:00:13].', 'name': 'Brand Visuals'}, {'category': 'Brand', 'criteria': 'The branded product names or generic product categories are heard or mentioned in the audio or speech at any time in the video.', 'detected': False, 'id': 'b_product_mention_speech', 'llm_explanation': 'There is no audio in the video, therefore the products are not mentioned.', 'name': 'Product Mention (Speech)'}, {'category': 'Brand', 'criteria': 'The branded product names or generic product categories are present in any text or overlay at any time in the video.', 'detected': True, 'id': 'b_product_mention_text', 'llm_explanation': 'The following product categories are mentioned at the following timestamps: \\n[00:00:05] phone\\n[00:00:07] watch\\n[00:00:08] buds\\nThe following branded product is mentioned at the following timestamp: \\n[00:00:13] Google Pixel 8', 'name': 'Product Mention (Text)'}, {'category': 'Brand', 'criteria': 'A product or branded packaging is visually present at any time in the video. Where the product is a service a relevant substitute should be shown such as via a branded app or branded service personnel.', 'detected': True, 'id': 'b_product_visuals', 'llm_explanation': 'The following products are visually present in the video at the following timestamps:\\n[00:00:00] Google Pixel watch\\n[00:00:01] Google Pixel phone\\n[00:00:02] Google Pixel watch\\n[00:00:03] Google pixel buds in a white case\\n[00:00:05] Google Pixel phone\\n[00:00:07] Google pixel watch\\n[00:00:08]-[00:00:10] Google Pixel buds\\n[00:00:13] Google Pixel phone.', 'name': 'Product Visuals'}, {'category': 'Connect', 'criteria': 'The pace of the video is greater than 2 seconds per shot/frame.', 'detected': False, 'id': 'c_overall_pacing', 'llm_explanation': 'The pace of the video is less than 2 seconds per shot/frame.', 'name': 'Overall Pacing'}, {'category': 'Connect', 'criteria': 'People are shown in any capacity at any time in the video. Any human body parts are acceptable to pass this guideline. Alternate representations of people such as Animations or Cartoons ARE acceptable.', 'detected': False, 'id': 'c_presence_of_people', 'llm_explanation': 'There are no people present at any time in the video.', 'name': 'Presence of People'}, {'category': 'Connect', 'criteria': 'There is a close up of a human face at any time in the video.', 'detected': False, 'id': 'c_visible_face_close_up', 'llm_explanation': 'There is no close up of a human face at any time in the video.', 'name': 'Visible Face (Close Up)'}, {'category': 'Direct', 'criteria': \"A 'Call To Action' phrase is heard or mentioned in the audio or speech at any time in the video.\", 'detected': False, 'id': 'd_call_to_action_speech', 'llm_explanation': 'There is no audio in the video, therefore there is no call to action mentioned in the speech.', 'name': 'Call To Action (Speech)'}, {'category': 'Direct', 'criteria': \"A 'Call To Action' phrase is detected in the video supers (overlaid text) at any time in the video.\", 'detected': False, 'id': 'd_call_to_action_text', 'llm_explanation': 'There is no call to action detected in the video supers (overlaid text).', 'name': 'Call To Action (Text)'}] \n",
            "\n",
            "/content/abcd-detector-input/Google/videos/12345_google_pixel_portfolio.mp4 \n",
            "\n",
            "***** ABCD Assessment for brand Google ***** \n",
            "\n",
            "Asset name: gs://abcd-detector-input/Google/videos/12345_google_pixel_portfolio.mp4 \n",
            "\n",
            "***** ABCD Assessment using Annotations ***** \n",
            "\n",
            "Video score: 43.48%, adherence (10/23)\n",
            "\n",
            "Asset result: ❌ Needs Review \n",
            "\n",
            "Evaluated Features: \n",
            "\n",
            " * ✅ Dynamic Start\n",
            " * ✅ Quick Pacing\n",
            " * ✅ Quick Pacing (First 5 seconds)\n",
            " * ✅ Supers\n",
            " * ❌ Supers with Audio\n",
            " * ❌ Brand Mention (Speech)\n",
            " * ❌ Brand Mention (Speech) (First 5 seconds)\n",
            " * ✅ Brand Visuals\n",
            " * ✅ Brand Visuals (First 5 seconds)\n",
            " * ❌ Product Mention (Speech)\n",
            " * ❌ Product Mention (Speech) (First 5 seconds)\n",
            " * ✅ Product Mention (Text)\n",
            " * ❌ Product Mention (Text) (First 5 seconds)\n",
            " * ✅ Product Visuals\n",
            " * ✅ Product Visuals (First 5 seconds)\n",
            " * ✅ Overall Pacing\n",
            " * ❌ Presence of People\n",
            " * ❌ Presence of People (First 5 seconds)\n",
            " * ❌ Visible Face (First 5 seconds)\n",
            " * ❌ Visible Face (Close Up)\n",
            " * ❌ Audio Early (First 5 seconds)\n",
            " * ❌ Call To Action (Speech)\n",
            " * ❌ Call To Action (Text)\n",
            "\n",
            "\n",
            "***** ABCD Assessment using LLMs ***** \n",
            "\n",
            "Video score: 43.48%, adherence (10/23)\n",
            "\n",
            "Asset result: ❌ Needs Review \n",
            "\n",
            "Evaluated Features: \n",
            "\n",
            " * ✅ Dynamic Start\n",
            " * ✅ Quick Pacing\n",
            " * ✅ Quick Pacing (First 5 seconds)\n",
            " * ✅ Supers\n",
            " * ❌ Supers with Audio\n",
            " * ❌ Brand Mention (Speech)\n",
            " * ❌ Brand Mention (Speech) (First 5 seconds)\n",
            " * ✅ Brand Visuals\n",
            " * ✅ Brand Visuals (First 5 seconds)\n",
            " * ❌ Product Mention (Speech)\n",
            " * ❌ Product Mention (Speech) (First 5 seconds)\n",
            " * ✅ Product Mention (Text)\n",
            " * ✅ Product Mention (Text) (First 5 seconds)\n",
            " * ✅ Product Visuals\n",
            " * ✅ Product Visuals (First 5 seconds)\n",
            " * ❌ Overall Pacing\n",
            " * ❌ Presence of People\n",
            " * ❌ Presence of People (First 5 seconds)\n",
            " * ❌ Visible Face (First 5 seconds)\n",
            " * ❌ Visible Face (Close Up)\n",
            " * ❌ Audio Early (First 5 seconds)\n",
            " * ❌ Call To Action (Speech)\n",
            " * ❌ Call To Action (Text)\n",
            "\n",
            "\n",
            "Storing ABCD assessment for video gs://abcd-detector-input/Google/videos/12345_google_pixel_portfolio.mp4 in BigQuery... \n",
            "\n",
            "The dataset tightlock-test.abcd_detector_ds was successfully created. \n",
            "\n",
            "The table tightlock-test.abcd_detector_ds.abcd_assessments was successfully created. \n",
            "\n",
            "Inserting 23 rows into BQ... \n",
            "\n",
            "Rows inserted in tightlock-test.abcd_detector_ds.abcd_assessments successfully! Total rows in table 23. \n",
            "\n",
            "\n",
            "\n",
            "Processing ABCD Assessment for video gs://abcd-detector-input/Google/videos/67890_google_pixel_portfolio.mp4... \n",
            "\n",
            "REDUCED: gs://abcd-detector-input/ABCD/abcd-detector-input/Google/videos/67890_google_pixel_portfolio_mp4/reduced_1st_5_secs.mp4 \n",
            "\n",
            "Shortening video gs://abcd-detector-input/Google/videos/67890_google_pixel_portfolio.mp4. \n",
            "\n",
            "Moviepy - Building video reduced/buffer_reduced.mp4.\n",
            "MoviePy - Writing audio in buffer_reducedTEMP_MPY_wvf_snd.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video reduced/buffer_reduced.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready reduced/buffer_reduced.mp4\n",
            "\n",
            "Processing video gs://abcd-detector-input/Google/videos/67890_google_pixel_portfolio.mp4 for [<Feature.SPEECH_TRANSCRIPTION: 6>] annotations...\n",
            "\n",
            "Processing video gs://abcd-detector-input/Google/videos/67890_google_pixel_portfolio.mp4 for [<Feature.TEXT_DETECTION: 7>, <Feature.SHOT_CHANGE_DETECTION: 2>, <Feature.LOGO_RECOGNITION: 12>, <Feature.LABEL_DETECTION: 1>] annotations...\n",
            "\n",
            "Processing video gs://abcd-detector-input/Google/videos/67890_google_pixel_portfolio.mp4 for [<Feature.PERSON_DETECTION: 14>] annotations...\n",
            "\n",
            "Processing video gs://abcd-detector-input/Google/videos/67890_google_pixel_portfolio.mp4 for [<Feature.FACE_DETECTION: 4>] annotations...\n",
            "\n",
            "Finished processing video gs://abcd-detector-input/Google/videos/67890_google_pixel_portfolio.mp4 for [<Feature.FACE_DETECTION: 4>] annotations...\n",
            "\n",
            "\n",
            "Finished processing video gs://abcd-detector-input/Google/videos/67890_google_pixel_portfolio.mp4 for [<Feature.SPEECH_TRANSCRIPTION: 6>] annotations...\n",
            "\n",
            "\n",
            "Finished processing video gs://abcd-detector-input/Google/videos/67890_google_pixel_portfolio.mp4 for [<Feature.TEXT_DETECTION: 7>, <Feature.SHOT_CHANGE_DETECTION: 2>, <Feature.LOGO_RECOGNITION: 12>, <Feature.LABEL_DETECTION: 1>] annotations...\n",
            "\n",
            "\n",
            "Finished processing video gs://abcd-detector-input/Google/videos/67890_google_pixel_portfolio.mp4 for [<Feature.PERSON_DETECTION: 14>] annotations...\n",
            "\n",
            "Starting ABCD evaluation using annotations... \n",
            "\n",
            "Annotation evaluation for feature Dynamic Start...\n",
            "Dynamic Start: True \n",
            "\n",
            "Annotation evaluation for feature Quick Pacing...\n",
            "Quick Pacing: True \n",
            "\n",
            "Annotation evaluation for feature Quick Pacing (First 5 seconds)...\n",
            "Quick Pacing (First 5 seconds): True \n",
            "\n",
            "Annotation evaluation for feature Supers...\n",
            "Supers: True \n",
            "\n",
            "Annotation evaluation for feature Supers with Audio...\n",
            "Supers with Audio: False \n",
            "\n",
            "Annotation evaluation for feature Brand Mention (Speech)...\n",
            "Brand Mention (Speech): False \n",
            "\n",
            "Annotation evaluation for feature Brand Mention (Speech) (First 5 seconds)...\n",
            "Brand Mention (Speech) (First 5 seconds): False \n",
            "\n",
            "Annotation evaluation for feature Brand Visuals...\n",
            "Brand Visuals: True \n",
            "\n",
            "Annotation evaluation for feature Brand Visuals (First 5 seconds)...\n",
            "Brand Visuals (First 5 seconds): True \n",
            "\n",
            "Annotation evaluation for feature Product Mention (Speech)...\n",
            "Product Mention (Speech): False \n",
            "\n",
            "Annotation evaluation for feature Product Mention (Speech) (First 5 seconds)...\n",
            "Product Mention (Speech) (First 5 seconds): False \n",
            "\n",
            "Annotation evaluation for feature Product Mention (Text)...\n",
            "Product Mention (Text): True \n",
            "\n",
            "Annotation evaluation for feature Product Mention (Text) (First 5 seconds)...\n",
            "Product Mention (Text) (First 5 seconds): False \n",
            "\n",
            "Annotation evaluation for feature Product Visuals...\n",
            "No Frame Label annotations found. Skipping Product Visuals Frame Label evaluation with Video Intelligence API.\n",
            "Product Visuals: True \n",
            "\n",
            "Annotation evaluation for feature Product Visuals (First 5 seconds)...\n",
            "No Frame Label annotations found. Skipping Product Visuals (First 5 seconds) Frame Label evaluation with Video Intelligence API.\n",
            "Product Visuals (First 5 seconds): True \n",
            "\n",
            "Annotation evaluation for feature Overall Pacing...\n",
            "Overall Pacing: True \n",
            "\n",
            "Annotation evaluation for feature Presence of People...\n",
            "No People annotations found. Skipping Presence of People evaluation with Video Intelligence API.\n",
            "Presence of People: False \n",
            "\n",
            "Annotation evaluation for feature Presence of People (First 5 seconds)...\n",
            "No People annotations found. Skipping Presence of People (First 5 seconds) evaluation with Video Intelligence API.\n",
            "Presence of People (First 5 seconds): False \n",
            "\n",
            "Annotation evaluation for feature Visible Face (First 5 seconds)...\n",
            "No Face annotations found. Skipping Visible Face (First 5 seconds) evaluation with Video Intelligence API.\n",
            "Visible Face (First 5 seconds): False \n",
            "\n",
            "Annotation evaluation for feature Visible Face (Close Up)...\n",
            "No Face annotations found. Skipping Visible Face (Close Up) evaluation with Video Intelligence API.\n",
            "Visible Face (Close Up): False \n",
            "\n",
            "Annotation evaluation for feature Audio Early (First 5 seconds)...\n",
            "Audio Early (First 5 seconds): False \n",
            "\n",
            "Annotation evaluation for feature Call To Action (Speech)...\n",
            "Call To Action (Speech): False \n",
            "\n",
            "Annotation evaluation for feature Call To Action (Text)...\n",
            "Call To Action (Text): False \n",
            "\n",
            "Starting ABCD evaluation using LLMs... \n",
            "\n",
            "Starting LLM evaluation for features grouped by first_5_secs_video... \n",
            "Starting LLM evaluation for features grouped by full_video... \n",
            "\n",
            "\n",
            "***Powered by LLMs*** \n",
            "\n",
            " FEATURES in group first_5_secs_video: \n",
            "\n",
            " [{'category': 'Attract', 'criteria': 'The first shot in the video changes in less than 3 seconds.', 'detected': True, 'id': 'a_dynamic_start', 'llm_explanation': 'The first shot of the video starts at 00:00:00 and changes to a shot of a blue Google Pixel phone at 00:00:01, which is less than 3 seconds.', 'name': 'Dynamic Start'}, {'category': 'Attract', 'criteria': 'There are at least 5 shot changes or visual cuts detected in the video. These include hard cuts, soft transitions and camera changes such as camera pans, swipes, zooms, depth of field changes, tracking shots and movement of the camera.', 'detected': True, 'id': 'a_quick_pacing_1st_secs', 'llm_explanation': 'The video has more than 5 shot changes. Number of shots: 6\\n1. 00:00:00 - 00:00:01 Google Pixel Watch\\n2. 00:00:01 - 00:00:02 Google Pixel phone\\n3. 00:00:02 - 00:00:03 Google Pixel Watch\\n4. 00:00:03 - 00:00:04 Google Pixel Buds\\n5. 00:00:04 - 00:00:05 Text \"The only\"\\n6. 00:00:05 - 00:00:06 Text \"Phone\"', 'name': 'Quick Pacing (First 5 seconds)'}, {'category': 'Brand', 'criteria': 'The brand name is heard in the audio or speech in the video.', 'detected': False, 'id': 'b_brand_mention_speech_1st_5_secs', 'llm_explanation': 'The brand name \"Google\" is not heard in the speech of the video.', 'name': 'Brand Mention (Speech) (First 5 seconds)'}, {'category': 'Brand', 'criteria': 'Branding, defined as the brand name or brand logo are shown in-situation or overlaid in the video.', 'detected': True, 'id': 'b_brand_visuals_1st_5_secs', 'llm_explanation': 'The brand name \"Google\" is shown in the video at [00:00:00]', 'name': 'Brand Visuals (First 5 seconds)'}, {'category': 'Brand', 'criteria': 'The branded product names or generic product categories are heard or mentioned in the audi or speech in the the video.', 'detected': False, 'id': 'b_product_mention_speech_1st_5_secs', 'llm_explanation': 'None of the mentioned products or categories are heard in the speech of the video.', 'name': 'Product Mention (Speech) (First 5 seconds)'}, {'category': 'Brand', 'criteria': 'The branded product names or generic product categories are present in any text or overlay in the video.', 'detected': True, 'id': 'b_product_mention_text_1st_5_secs', 'llm_explanation': 'The product category \"phone\" is present in the video at [00:00:05]', 'name': 'Product Mention (Text) (First 5 seconds)'}, {'category': 'Brand', 'criteria': 'A product or branded packaging is visually present at any time in the video. Where the product is a service a relevant substitute should be shown such as via a branded app or branded service personnel.', 'detected': True, 'id': 'b_product_visuals_1st_5_secs', 'llm_explanation': 'The Google Pixel phone is shown at [00:00:01], Google Pixel Watch at [00:00:00 and 00:00:02] and Google Pixel Buds at [00:00:03]', 'name': 'Product Visuals (First 5 seconds)'}, {'category': 'Connect', 'criteria': 'People are shown in any capacity in the video. Any human body parts are acceptable to pass this guideline. Alternate representations of people such as Animations or Cartoons ARE acceptable.', 'detected': False, 'id': 'c_presence_of_people_1st_5_secs', 'llm_explanation': 'No people are present in the video.', 'name': 'Presence of People (First 5 seconds)'}, {'category': 'Connect', 'criteria': 'At least one human face is present in the video. Alternate representations of people such as Animations or Cartoons ARE acceptable.', 'detected': False, 'id': 'c_visible_face', 'llm_explanation': 'No human face is present in the video.', 'name': 'Visible Face (First 5 seconds)'}, {'category': 'Direct', 'criteria': 'Speech is detected in the audio of the video.', 'detected': False, 'id': 'd_audio_speech_early_1st_5_secs', 'llm_explanation': 'No speech is detected in the audio of the video.', 'name': 'Audio Early (First 5 seconds)'}] \n",
            "\n",
            "***Powered by LLMs*** \n",
            "\n",
            " FEATURES in group full_video: \n",
            "\n",
            " [{'category': 'Attract', 'criteria': 'Within ANY 5 consecutive seconds there are 5 or more shots in the video. These include hard cuts, soft transitions and camera changes such as camera pans, swipes, zooms, depth of field changes, tracking shots and movement of the camera.', 'detected': True, 'id': 'a_quick_pacing', 'llm_explanation': 'Number of Shots: 6\\nTimestamps and shot descriptions:\\n[00:00:00 to 00:00:01] Google Pixel Watch and text Google Pixel.\\n[00:00:01 to 00:00:02] Close-up of light blue Google Pixel phone.\\n[00:00:02 to 00:00:03] Google Pixel Watch with a light blue band and the time 9:12 displayed.\\n[00:00:03 to 00:00:04] Google Pixel Buds in a white charging case.\\n[00:00:04 to 00:00:05] Text The only phone.\\n[00:00:05 to 00:00:06] Multiple Google Pixel phones of different colors in different positions.', 'name': 'Quick Pacing'}, {'category': 'Attract', 'criteria': 'Any supers (text overlays) have been incorporated at any time in the video.', 'detected': True, 'id': 'a_supers', 'llm_explanation': 'Supers are found throughout the video.\\n[00:00:00] Google Pixel\\n[00:00:04]-[00:00:05] The only phone\\n[00:00:07]-[00:00:08] engineered by Google\\n[00:00:12]-[00:00:14] Google Pixel 8', 'name': 'Supers'}, {'category': 'Attract', 'criteria': 'The speech heard in the audio of the video matches OR is contextually supportive of the overlaid text shown on screen.', 'detected': True, 'id': 'a_supers_with_audio', 'llm_explanation': 'The speech in the audio mentions the Pixel 8, which matches the overlaid text \"Google Pixel 8\" shown at [00:00:12]-[00:00:14] in the video.', 'name': 'Supers with Audio'}, {'category': 'Brand', 'criteria': 'The brand name is heard in the audio or speech at any time in the video.', 'detected': True, 'id': 'b_brand_mention_speech', 'llm_explanation': 'The brand Google is heard in the speech of the video at [00:00:12] followed by Pixel 8.', 'name': 'Brand Mention (Speech)'}, {'category': 'Brand', 'criteria': 'Branding, defined as the brand name or brand logo are shown in-situation or overlaid at any time in the video.', 'detected': True, 'id': 'b_brand_visuals', 'llm_explanation': 'The brand name Google is displayed at [00:00:00] and [00:00:12], also the Google logo \"G\" is shown throughout the video on the presented products.', 'name': 'Brand Visuals'}, {'category': 'Brand', 'criteria': 'The branded product names or generic product categories are heard or mentioned in the audio or speech at any time in the video.', 'detected': True, 'id': 'b_product_mention_speech', 'llm_explanation': 'The product Google Pixel 8 is mentioned at [00:00:12].', 'name': 'Product Mention (Speech)'}, {'category': 'Brand', 'criteria': 'The branded product names or generic product categories are present in any text or overlay at any time in the video.', 'detected': True, 'id': 'b_product_mention_text', 'llm_explanation': 'The product Google Pixel is presented as text overlay from [00:00:00] to [00:00:01]. \\nThe product category phone is mentioned in the text The only phone at [00:00:04]-[00:00:05].\\nThe Google Pixel 8 is presented in text from [00:00:12] to [00:00:14].', 'name': 'Product Mention (Text)'}, {'category': 'Brand', 'criteria': 'A product or branded packaging is visually present at any time in the video. Where the product is a service a relevant substitute should be shown such as via a branded app or branded service personnel.', 'detected': True, 'id': 'b_product_visuals', 'llm_explanation': 'The following products are visually present:\\n[00:00:00]-[00:00:01] Google Pixel Watch with red band.\\n[00:00:01]-[00:00:02] Google Pixel phone in light blue.\\n[00:00:02]-[00:00:03] Google Pixel watch with light blue band.\\n[00:00:03]-[00:00:04] Google Pixel Buds in white charging case.\\n[00:00:05]-[00:00:07] Google Pixel Phones in different colors and positions.\\n[00:00:07]-[00:00:08] Google Pixel watch with red band.\\n[00:00:08]-[00:00:10] Google Pixel buds, light blue and white and white and beige.\\n[00:00:12]-[00:00:14] Google Pixel phone in light blue.', 'name': 'Product Visuals'}, {'category': 'Connect', 'criteria': 'The pace of the video is greater than 2 seconds per shot/frame.', 'detected': False, 'id': 'c_overall_pacing', 'llm_explanation': 'The pace of the video is around one second per shot and hence less than 2 seconds.', 'name': 'Overall Pacing'}, {'category': 'Connect', 'criteria': 'People are shown in any capacity at any time in the video. Any human body parts are acceptable to pass this guideline. Alternate representations of people such as Animations or Cartoons ARE acceptable.', 'detected': False, 'id': 'c_presence_of_people', 'llm_explanation': 'No people are present at any time in the video.', 'name': 'Presence of People'}, {'category': 'Connect', 'criteria': 'There is a close up of a human face at any time in the video.', 'detected': False, 'id': 'c_visible_face_close_up', 'llm_explanation': 'No close-up shots of human faces are present in the video.', 'name': 'Visible Face (Close Up)'}, {'category': 'Direct', 'criteria': \"A 'Call To Action' phrase is heard or mentioned in the audio or speech at any time in the video.\", 'detected': False, 'id': 'd_call_to_action_speech', 'llm_explanation': 'No call to action is heard in the speech of the video.', 'name': 'Call To Action (Speech)'}, {'category': 'Direct', 'criteria': \"A 'Call To Action' phrase is detected in the video supers (overlaid text) at any time in the video.\", 'detected': False, 'id': 'd_call_to_action_text', 'llm_explanation': 'No call to action is detected in the overlaid text in the video.', 'name': 'Call To Action (Text)'}] \n",
            "\n",
            "/content/abcd-detector-input/Google/videos/67890_google_pixel_portfolio.mp4 \n",
            "\n",
            "***** ABCD Assessment for brand Google ***** \n",
            "\n",
            "Asset name: gs://abcd-detector-input/Google/videos/67890_google_pixel_portfolio.mp4 \n",
            "\n",
            "***** ABCD Assessment using Annotations ***** \n",
            "\n",
            "Video score: 43.48%, adherence (10/23)\n",
            "\n",
            "Asset result: ❌ Needs Review \n",
            "\n",
            "Evaluated Features: \n",
            "\n",
            " * ✅ Dynamic Start\n",
            " * ✅ Quick Pacing\n",
            " * ✅ Quick Pacing (First 5 seconds)\n",
            " * ✅ Supers\n",
            " * ❌ Supers with Audio\n",
            " * ❌ Brand Mention (Speech)\n",
            " * ❌ Brand Mention (Speech) (First 5 seconds)\n",
            " * ✅ Brand Visuals\n",
            " * ✅ Brand Visuals (First 5 seconds)\n",
            " * ❌ Product Mention (Speech)\n",
            " * ❌ Product Mention (Speech) (First 5 seconds)\n",
            " * ✅ Product Mention (Text)\n",
            " * ❌ Product Mention (Text) (First 5 seconds)\n",
            " * ✅ Product Visuals\n",
            " * ✅ Product Visuals (First 5 seconds)\n",
            " * ✅ Overall Pacing\n",
            " * ❌ Presence of People\n",
            " * ❌ Presence of People (First 5 seconds)\n",
            " * ❌ Visible Face (First 5 seconds)\n",
            " * ❌ Visible Face (Close Up)\n",
            " * ❌ Audio Early (First 5 seconds)\n",
            " * ❌ Call To Action (Speech)\n",
            " * ❌ Call To Action (Text)\n",
            "\n",
            "\n",
            "***** ABCD Assessment using LLMs ***** \n",
            "\n",
            "Video score: 56.52%, adherence (13/23)\n",
            "\n",
            "Asset result: ❌ Needs Review \n",
            "\n",
            "Evaluated Features: \n",
            "\n",
            " * ✅ Dynamic Start\n",
            " * ✅ Quick Pacing\n",
            " * ✅ Quick Pacing (First 5 seconds)\n",
            " * ✅ Supers\n",
            " * ✅ Supers with Audio\n",
            " * ✅ Brand Mention (Speech)\n",
            " * ❌ Brand Mention (Speech) (First 5 seconds)\n",
            " * ✅ Brand Visuals\n",
            " * ✅ Brand Visuals (First 5 seconds)\n",
            " * ✅ Product Mention (Speech)\n",
            " * ❌ Product Mention (Speech) (First 5 seconds)\n",
            " * ✅ Product Mention (Text)\n",
            " * ✅ Product Mention (Text) (First 5 seconds)\n",
            " * ✅ Product Visuals\n",
            " * ✅ Product Visuals (First 5 seconds)\n",
            " * ❌ Overall Pacing\n",
            " * ❌ Presence of People\n",
            " * ❌ Presence of People (First 5 seconds)\n",
            " * ❌ Visible Face (First 5 seconds)\n",
            " * ❌ Visible Face (Close Up)\n",
            " * ❌ Audio Early (First 5 seconds)\n",
            " * ❌ Call To Action (Speech)\n",
            " * ❌ Call To Action (Text)\n",
            "\n",
            "\n",
            "Storing ABCD assessment for video gs://abcd-detector-input/Google/videos/67890_google_pixel_portfolio.mp4 in BigQuery... \n",
            "\n",
            "The dataset tightlock-test.abcd_detector_ds already exists. \n",
            "\n",
            "The table tightlock-test.abcd_detector_ds.abcd_assessments already exists. \n",
            "\n",
            "Inserting 23 rows into BQ... \n",
            "\n",
            "Rows inserted in tightlock-test.abcd_detector_ds.abcd_assessments successfully! Total rows in table 46. \n",
            "\n",
            "Finished ABCD assessment. \n",
            "\n",
            "ABCD assessment took --- 3.493089258670807 mins. --- \n",
            "\n"
          ]
        }
      ]
    }
  ]
}